Process:
  SFT:
    Train: True # If set to true, it starts train, esle inference.
  RewardModel:
    FineTune: False

Model:
  model_name: "meta-llama/Llama-3.2-1B-Instruct" # "Qwen/Qwen2.5-Coder-0.5B"
  output_dir: "./Llama-3.2-1B-Instruct" # directory to save the fine-tuned model and tokenizer

Data:
  dataset_file: "/content/Blender-Node-Copilot/node_copilot/data/training_data.json" # file
  dataset_path: "/content/" # root

Train:
  max_length: 2000
  num_train_epochs: 10
  learning_rate: 3e-4
  LORA:
    rank_dimension: 6
    lora_alpha: 8
    lora_dropout: 0.05

Logging:
  logging_steps: 10
  logging_dir: './logs'
  output_dir: './Llama-3.2-1B-Instruct'
  report_to: 'mlflow'

